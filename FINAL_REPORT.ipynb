{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a71fc5-89dd-4871-8f70-a46cf8dfd9b2",
   "metadata": {},
   "source": [
    "Yang Yu (yy5bm@virginia.edu) DS 5001 Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e45bc-5bdf-4072-aece-2b0b7c02f263",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa5a3b-4d47-4bf9-952e-24216ee56be8",
   "metadata": {},
   "source": [
    "This project aims at exploring a corpus of Machine Learning patents published between 1997 and 2003 in the U.S., with the goal of identifying patents that are both innovative and inspire future works. \n",
    "\n",
    "The corpus contains 9399 patents, with text description, publication year, and CPC classification by USPTO for each patent.The OHCO has two levels: patent, sentence. We are not able to parse by paragraph because the text data has no double line breaks.\n",
    "\n",
    "We follow Kelly et al. (2021) and compute a novel measure of patent importance based on a modified version of TFIDF, from which we are able to identify patents that are of utmost importance. In addition, we perform four data models: PCA, LDA, word2vec, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81620e-4f57-4473-a801-dd582ce33f31",
   "metadata": {},
   "source": [
    "# Source data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6020f7-b132-4a6a-b69a-8ccd1f0a443e",
   "metadata": {},
   "source": [
    "We collect data from three sources. \n",
    "\n",
    "First, we download from USPTO official website the Artificial Intelligence Patent Dataset (AIPD) in the formate of DTA https://www.uspto.gov/ip-policy/economic-research/research-datasets/artificial-intelligence-patent-dataset. This dataset includes all patents issued between 1976 and 2020 that are associated with one or more of several AI technology components (including machine learning, natural language processing, computer vision, speech, knowledge processing, AI hardware, evolutionary computation, and planning and control), and we further narrow down to the patents that are labelled 'machine learning'. We keep an observation if it belongs to 'machine learning' and was published between 1997 and 2003. The final dataset contains 9,399 observations, for each observation, we observe the patent id, publication date, and AI technology category. This dataset helps us identify all patents on machine learning.\n",
    "\n",
    "Second, we download patent description data from 1997 to 2003 from PatentsView in the format of TSV. It is a web-based platform created and maintained by the United States Patent and Trademark Office (USPTO) that provides data on U.S. patents and patent applications https://patentsview.org/download/draw_desc_text. The dataset has over 1 million observations, each observation includes a patent id and its text description. The mean of text length is 3886. \n",
    "\n",
    "Finally, we download CPC classification data from PatentsView in the format of TSV https://patentsview.org/download/data-download-tables. This dataset provides information on the current CPC classifications of all granted U.S. patents. It consists of 48,473,812 observations, each observation is a patent and its CPC classification. \n",
    "\n",
    "We take the first dataset as our master dataset, and match to it the description and classification data from the second and third datasets based on the shared patent id. Table 1 shows what our final dataset looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b88b7a-1a5a-413a-a2ed-208f4299febe",
   "metadata": {},
   "source": [
    "Table 1: LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09aef6-4ac2-4f6a-a8eb-0185d9eca037",
   "metadata": {},
   "source": [
    "<img src=\"tab1.png\" alt=\"Alt text\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42f522-ff52-4035-a682-966dcc195a08",
   "metadata": {},
   "source": [
    "# Box link\n",
    "\n",
    "Below is the definition and link to the source files:\n",
    "\n",
    "- Data: raw data we used, https://virginia.box.com/s/hu8gh60xpevsrkfq2a0otz1bpyevz0fx\n",
    "\n",
    "- LIB: libraray table, https://virginia.box.com/s/1td9sjj2r0wj2lj83yrlzun10561a6zz\n",
    "\n",
    "- TOKENS: token table, https://virginia.box.com/s/e1cpk5mu5gxoptxdjuvj4hrgniso62x6\n",
    "\n",
    "- VOCAB, vocab table, https://virginia.box.com/s/bcn9523mqk7ssy4r9l2lqnm8ybs7ucq0\n",
    "\n",
    "- BOW: bag of words, https://virginia.box.com/s/2e238fvbj426u5h0r0oh5l5ulcn7tu0r\n",
    "\n",
    "- LOADINGS_sk: loadings in PCA, https://virginia.box.com/s/pzrddfzdvril43vjkzku6l5e73qshmkq\n",
    "\n",
    "- DCM_sk: DCM table in PCA, https://virginia.box.com/s/dwblbfqm9jwby75ngbkiucac7ygkg1tr\n",
    "\n",
    "- THETA: theta table in Topic model, https://virginia.box.com/s/scg1u475eydp20wsd6o796qqrovfkfbc\n",
    "\n",
    "- PHI: phi table in topic model, https://virginia.box.com/s/bbcl1eamnzgsjyzirt32lelwcaubdlnb\n",
    "\n",
    "- Coord: Terms and embeddings, added to the VOCAB table, https://virginia.box.com/s/7zqtov9rgrrez832vf8z2r1c6907hwk5\n",
    "\n",
    "- V: Sentiment and emotion values added to VOCAB, https://virginia.box.com/s/0bmfys62sa09rshlmbperjltnk9h3ul0\n",
    "\n",
    "- EMO_PTS: Sentiment and emotion value for each patent, https://virginia.box.com/s/37ls9cuepl0e2yexgv76glllyp36s6dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba82e4-a5b9-4974-86b0-ae813929e275",
   "metadata": {},
   "source": [
    "# Data Model\n",
    "## A new measure of TF-BIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2c215-4c26-468b-be9c-2857c62522e4",
   "metadata": {},
   "source": [
    "The goal in this section is to measure the importance of each patent. There are two dimensions in measuring the importance of a patent, novelty and influence. A patent is novel if it's unlike its predecessors, and is influential if it inspires subsequent research. Consistent with this spirit, we use backward and forward similarity to measure the novelty and influence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70654a25-e87b-4eac-94f9-cdf8173321b4",
   "metadata": {},
   "source": [
    "Instead of using the standard IDF in computing TFIDF, we follow Kelly et al. (2021) and use Backward IDF (BIDF). The reasoning is, timing is important for evaluating the novelty and influence. For example, if a concept such as 'machine learning' was first proposed in 1970 and becomes widespread in the subsequent patents, then using the traditional IDF will bias down the significance of 'machine learning' in the patent where it first showed up. Therefore, when computing IDF for a patent published in year $t$, we only use the pool of patents published before year $t$, and we call it BIDF.\n",
    "\n",
    "Formally, to compute the TF-BIDF of a word $w$ in patent $i$, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56632995-8003-4aa0-a1b0-e5a4db2b22df",
   "metadata": {},
   "source": [
    "$$TF_{w,i} = \\frac{c_{w,i}}{\\sum_k c_{k,i}}\\rightarrow \\text{Frequency of word w in patent i}$$\n",
    "\n",
    "$$BIDF_{w,i} = \\log\\left(\\frac{\\text{# of patents prior to }t}{1+\\text{# of patents published two years prior to t that include word w}}\\right)$$\n",
    "\n",
    "$$t\\text{: the publication year of patent i}$$\n",
    "\n",
    "$$TFBIDF_{w,i}=TF_{w,i}\\times BIDF_{w,i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b01ac9-bae2-40db-bce6-83f67521447f",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14381ba5-b4f8-4e1f-93f5-24604b9c962e",
   "metadata": {},
   "source": [
    "Because the TFIDF table is large, we first perform PCA and then select a smaller set of components that explain 80% variance before moving on to compute patent importance. By Figure 1, we keep the top 2000 components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af3d93-ad76-495f-bafd-68e0f42e96b3",
   "metadata": {},
   "source": [
    "Figure 1: Cumulative explained variance by number of components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111513a5-1efd-496c-8344-b03382730014",
   "metadata": {},
   "source": [
    "<img src=\"fig1.png\" alt=\"Alt text\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b2a04-6577-45db-a113-e23aa760d868",
   "metadata": {},
   "source": [
    "## Measure of importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc406b-8193-408c-a284-de3d2a5cef78",
   "metadata": {},
   "source": [
    "Since we use a two-year window to compute TF-BIDF, we drop patents published in 1997 and 1998 because their BIDF are not proper. Then we are left with patents from 1999 to 2003. Again we use two-year window to compute backward and forward similarity, which means we can only compute backward similarity for patents after (incl.) 2001 and forward similarity for patents before (incl.) 2001. As a result, we can only compute the importance measure that considers both backward and forward similarity for patents in 2001. \n",
    "\n",
    "We use 'cosine' distance to measure the similarity between two patents. Formally, for patent $i$, its backward similarity (BS) and forward similarity (FS are defined as following:\n",
    "\n",
    "$$BS_i=\\sum_{j\\in B(i)} \\text{cosine distance}(i,j)$$\n",
    "\n",
    "$$FS_i=\\sum_{j\\in F(i)} \\text{cosine distance}(i,j)$$\n",
    "\n",
    "$B(i), F(i)$ are the set of patents that were issued within two years before and after the year patent $i$ was published. The importance of patent $i$, $\\rho_i$ is formally defined as\n",
    "\n",
    "$$\\rho_i=\\frac{FS_i}{BS_i}$$\n",
    "\n",
    "Figure 2, 3, 4 show the distribution for BS, FS, and $\\rho$. The key message from Figure 4 is that the importance of patent has fat left tail and long right tail, meaning that most patents are 'not' important, but there are few that are really valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd645a-6545-4872-a0eb-5a357a1e188c",
   "metadata": {},
   "source": [
    "Figure 2: Backward similarity\n",
    "\n",
    "<img src=\"BS.png\" alt=\"Alt text\" width=\"600\" height=\"400\">\n",
    "\n",
    "Figure 3: Forward similarity\n",
    "\n",
    "<img src=\"FS.png\" alt=\"Alt text\" width=\"600\" height=\"400\">\n",
    "\n",
    "Figure 4: Importance\n",
    "\n",
    "<img src=\"importance.png\" alt=\"Alt text\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67561164-d402-45d2-afe4-3ce9609bf38d",
   "metadata": {},
   "source": [
    "## Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfd725-0247-4395-ab78-73c5f13c7b85",
   "metadata": {},
   "source": [
    "In estimating the LDA topic model, we only keep nouns, and set max feature as 4000 and topic number as 9, the topic number is consistant with the number of CPC classification. We perform LDA only on patents published in 1997 for the sake of computation capacity.\n",
    "\n",
    "The $\\theta$ and $\\phi$ tables are shown in Table 2 and 3. The most important words in each topic is shown in Table 4. The topic similarity is shown in Figure 5.\n",
    "\n",
    "By Table 4, the key insight is machine learning technology is applied in different fields. T4 is apparently a topic associated with biology and pharma industry, T8 is probably related to brain and neuroscience. Figure 5 shows how similar each topic is to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b138a06-c849-4f60-9092-fa1d993d239e",
   "metadata": {},
   "source": [
    "Table 2: $\\theta$\n",
    "\n",
    "<img src=\"THETA.png\" alt=\"Alt text\">\n",
    "\n",
    "Table 3: $\\phi$\n",
    "\n",
    "<img src=\"PHI.png\" alt=\"Alt text\">\n",
    "\n",
    "Table 4: Topic components\n",
    "\n",
    "<img src=\"topic.png\" alt=\"Alt text\">\n",
    "\n",
    "Figure 5: Topic similarity\n",
    "\n",
    "<img src=\"hac.png\" alt=\"Alt text\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b796f-a1b9-49fd-9dd4-09cbd1416ae0",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d371d1f-287a-4fee-aee0-7fb2eacb4598",
   "metadata": {},
   "source": [
    "For word embedding, we use machine learning patent published in 1997.\n",
    "\n",
    "The parameters chosen for word embedding are: window = 5, vector_size = 246, min_count = 50, workers = 4. Figure 6 shows a cluster of words that are close to each other. This cluster is mainly about words on biology, including cells, stem, antibody, and these are words that tend to go hand in hand with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80141f-0334-49fe-9996-2f255cb59835",
   "metadata": {},
   "source": [
    "Figure 6: Word embedding\n",
    "\n",
    "<img src=\"we.png\" alt=\"Alt text\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b801f-16ff-4ae5-8b57-df5ec110de08",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d51c2-7406-4e3d-a3f5-48e1707faf67",
   "metadata": {},
   "source": [
    "We use machine learning patent published in 1997 and compute the standard TFIDF based on which we perform sentiment analysis. We acknowledge that in principle, patent text is generally neutral and the result from sentiment analysis is not likely to be meaningful. We perform it for the purpose of this class. \n",
    "\n",
    "Figure 7 describes the distribution of emotion values for each patent. Most patents are neutral in terms of emotion, but there are few with low emotion values. To make sense of it, patents are usually about solving a problem, especially for the set of patents on pharma and biology, where words that describe diseases such as 'chronic', 'diagnosis' are not uncommon. Due to such nature of patents, we would expect that mechanically, some patents have low scores in their emotional values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb661013-5c92-4259-9c0f-1ec64421d962",
   "metadata": {},
   "source": [
    "Figure 7: Emotion value distribution\n",
    "\n",
    "<img src=\"sa.png\" alt=\"Alt text\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afd2db-dad4-4028-97ee-244367a166ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
